{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "import psycopg2\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "This project's aim is to give a wider view of the US I94 immigration data in the light of temperature data for further analysis of immigration data.We can conclude whether temperature affects the selection of destination cities for immigration.Our data model will be based on aggregating the I94 immigration data by destination city to form our first-dim table then aggregate city temperature data by city to create dim2 table. Both tables will be joined on destination city to form the fact table creating a final database to query on immigration events. \n",
    "\n",
    "#### I94 Immigration Data\n",
    "\n",
    "This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. This is where the data comes from.Check the sample data for more understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_path = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df_i94 = pd.read_sas(i94_path, 'sas7bdat', encoding=\"ISO-8859-1\")\n",
    "df_i94.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "df_im = pd.read_csv(\"immigration_data_sample.csv\")\n",
    "df_im.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the temperature data\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temp = pd.read_csv(fname, sep=',')\n",
    "# Display first 5 rows of df_temp\n",
    "df_temp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create a Spark session\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "spark = SparkSession.builder\\\n",
    "        .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\")\\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0,saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "        .enableHiveSupport().getOrCreate()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>count</th>\n",
       "      <th>biryear</th>\n",
       "      <th>admnum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3096313.0</td>\n",
       "      <td>3096313.0</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3.096074e+06</td>\n",
       "      <td>2.953856e+06</td>\n",
       "      <td>3.095511e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "      <td>3096313.0</td>\n",
       "      <td>3.095511e+06</td>\n",
       "      <td>3.096313e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.078652e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.049069e+02</td>\n",
       "      <td>3.032838e+02</td>\n",
       "      <td>2.055985e+04</td>\n",
       "      <td>1.073690e+00</td>\n",
       "      <td>2.057395e+04</td>\n",
       "      <td>4.176761e+01</td>\n",
       "      <td>1.845393e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.974232e+03</td>\n",
       "      <td>7.082885e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.763278e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.100269e+02</td>\n",
       "      <td>2.085832e+02</td>\n",
       "      <td>8.777339e+00</td>\n",
       "      <td>5.158963e-01</td>\n",
       "      <td>2.935697e+01</td>\n",
       "      <td>1.742026e+01</td>\n",
       "      <td>3.983910e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.742026e+01</td>\n",
       "      <td>2.215442e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>1.010000e+02</td>\n",
       "      <td>2.054500e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.517600e+04</td>\n",
       "      <td>-3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.902000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.577790e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.350000e+02</td>\n",
       "      <td>1.310000e+02</td>\n",
       "      <td>2.055200e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.056100e+04</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.962000e+03</td>\n",
       "      <td>5.603523e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.103507e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.130000e+02</td>\n",
       "      <td>2.130000e+02</td>\n",
       "      <td>2.056000e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.057000e+04</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.975000e+03</td>\n",
       "      <td>5.936094e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.654341e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.120000e+02</td>\n",
       "      <td>5.040000e+02</td>\n",
       "      <td>2.056700e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.057900e+04</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.986000e+03</td>\n",
       "      <td>9.350987e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.102785e+06</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.990000e+02</td>\n",
       "      <td>7.600000e+02</td>\n",
       "      <td>2.057400e+04</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>4.542700e+04</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.019000e+03</td>\n",
       "      <td>9.991557e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cicid      i94yr     i94mon        i94cit        i94res  \\\n",
       "count  3.096313e+06  3096313.0  3096313.0  3.096313e+06  3.096313e+06   \n",
       "mean   3.078652e+06     2016.0        4.0  3.049069e+02  3.032838e+02   \n",
       "std    1.763278e+06        0.0        0.0  2.100269e+02  2.085832e+02   \n",
       "min    6.000000e+00     2016.0        4.0  1.010000e+02  1.010000e+02   \n",
       "25%    1.577790e+06     2016.0        4.0  1.350000e+02  1.310000e+02   \n",
       "50%    3.103507e+06     2016.0        4.0  2.130000e+02  2.130000e+02   \n",
       "75%    4.654341e+06     2016.0        4.0  5.120000e+02  5.040000e+02   \n",
       "max    6.102785e+06     2016.0        4.0  9.990000e+02  7.600000e+02   \n",
       "\n",
       "            arrdate       i94mode       depdate        i94bir       i94visa  \\\n",
       "count  3.096313e+06  3.096074e+06  2.953856e+06  3.095511e+06  3.096313e+06   \n",
       "mean   2.055985e+04  1.073690e+00  2.057395e+04  4.176761e+01  1.845393e+00   \n",
       "std    8.777339e+00  5.158963e-01  2.935697e+01  1.742026e+01  3.983910e-01   \n",
       "min    2.054500e+04  1.000000e+00  1.517600e+04 -3.000000e+00  1.000000e+00   \n",
       "25%    2.055200e+04  1.000000e+00  2.056100e+04  3.000000e+01  2.000000e+00   \n",
       "50%    2.056000e+04  1.000000e+00  2.057000e+04  4.100000e+01  2.000000e+00   \n",
       "75%    2.056700e+04  1.000000e+00  2.057900e+04  5.400000e+01  2.000000e+00   \n",
       "max    2.057400e+04  9.000000e+00  4.542700e+04  1.140000e+02  3.000000e+00   \n",
       "\n",
       "           count       biryear        admnum  \n",
       "count  3096313.0  3.095511e+06  3.096313e+06  \n",
       "mean         1.0  1.974232e+03  7.082885e+10  \n",
       "std          0.0  1.742026e+01  2.215442e+10  \n",
       "min          1.0  1.902000e+03  0.000000e+00  \n",
       "25%          1.0  1.962000e+03  5.603523e+10  \n",
       "50%          1.0  1.975000e+03  5.936094e+10  \n",
       "75%          1.0  1.986000e+03  9.350987e+10  \n",
       "max          1.0  2.019000e+03  9.991557e+10  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port_code</th>\n",
       "      <th>port_city</th>\n",
       "      <th>port_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DTH</td>\n",
       "      <td>DUTCH HARBOR</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EGL</td>\n",
       "      <td>EAGLE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FRB</td>\n",
       "      <td>FAIRBANKS</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOM</td>\n",
       "      <td>HOMER</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HYD</td>\n",
       "      <td>HYDER</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JUN</td>\n",
       "      <td>JUNEAU</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5KE</td>\n",
       "      <td>KETCHIKAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KET</td>\n",
       "      <td>KETCHIKAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MOS</td>\n",
       "      <td>MOSES POINT INTERMEDIATE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NIK</td>\n",
       "      <td>NIKISKI</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NOM</td>\n",
       "      <td>NOM</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PKC</td>\n",
       "      <td>POKER CREEK</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ORI</td>\n",
       "      <td>PORT LIONS SPB</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SKA</td>\n",
       "      <td>SKAGWAY</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SNP</td>\n",
       "      <td>ST. PAUL ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   port_code                 port_city port_state\n",
       "0        ALC                     ALCAN         AK\n",
       "1        ANC                 ANCHORAGE         AK\n",
       "2        BAR  BAKER AAF - BAKER ISLAND         AK\n",
       "3        DAC             DALTONS CACHE         AK\n",
       "4        PIZ    DEW STATION PT LAY DEW         AK\n",
       "5        DTH              DUTCH HARBOR         AK\n",
       "6        EGL                     EAGLE         AK\n",
       "7        FRB                 FAIRBANKS         AK\n",
       "8        HOM                     HOMER         AK\n",
       "9        HYD                     HYDER         AK\n",
       "10       JUN                    JUNEAU         AK\n",
       "11       5KE                 KETCHIKAN         AK\n",
       "12       KET                 KETCHIKAN         AK\n",
       "13       MOS  MOSES POINT INTERMEDIATE         AK\n",
       "14       NIK                   NIKISKI         AK\n",
       "15       NOM                       NOM         AK\n",
       "16       PKC               POKER CREEK         AK\n",
       "17       ORI            PORT LIONS SPB         AK\n",
       "18       SKA                   SKAGWAY         AK\n",
       "19       SNP           ST. PAUL ISLAND         AK"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get port locations from SAS text file\n",
    "with open(\"./I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip() for x in content]\n",
    "ports = content[302:962]\n",
    "splitted_ports = [p.split(\"=\") for p in ports]\n",
    "port_codes = [x[0].replace(\"'\",\"\").strip() for x in splitted_ports]\n",
    "port_locations = [x[1].replace(\"'\",\"\").strip() for x in splitted_ports]\n",
    "port_cities = [x.split(\",\")[0] for x in port_locations]\n",
    "port_states = [x.split(\",\")[-1] for x in port_locations]\n",
    "df_pl = pd.DataFrame({\"port_code\" : port_codes, \"port_city\": port_cities, \"port_state\": port_states})\n",
    "df_pl.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "I94 immigration data - discarding all data points with the destination city code i94port is not a valid value (XXX, 99, NaN, etc)\n",
    "\n",
    "Temperature Data - discarding all data points where AverageTemperature is duplicate locations, and add the i94port of the location for each entry.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create dictionary of valid i94port codes\n",
    "re_obj = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "i94port_valid = {}\n",
    "with open('i94port_valid.txt') as f:\n",
    "     for line in f:\n",
    "         match = re_obj.search(line)\n",
    "         i94port_valid[match[1]]=[match[2]]\n",
    "\n",
    "# Clean I94 immigration data\n",
    "def clean_i94_data(file):\n",
    "    '''    \n",
    "    Input: Path to I94 immigration data file\n",
    "    Output: Spark dataframe of I94 immigration data with valid i94port\n",
    "    '''    \n",
    "    # Read I94 data into Spark\n",
    "    df_immigration = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "\n",
    "    # Filter out entries where i94port is invalid\n",
    "    df_immigration = df_immigration.filter(df_immigration.i94port.isin(list(i94port_valid.keys())))\n",
    "\n",
    "    return df_immigration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean I94 immigration data\n",
    "def clean_i94_data(file):\n",
    "    '''    \n",
    "    Input: Path to I94 immigration data file\n",
    "    Output: Spark dataframe of I94 immigration data with valid i94port\n",
    "    '''    \n",
    "    # Read I94 data into Spark\n",
    "    df_immigration = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "    return df_immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MI|20555.0|  57.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1959.0|09302016|  null|  null|     AZ|9.247103803E10|00602|      B1|\n",
      "| 19.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  63.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1953.0|09302016|  null|  null|     AZ|9.247139923E10|00602|      B2|\n",
      "| 20.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  57.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1959.0|09302016|  null|  null|     AZ|9.247161383E10|00602|      B2|\n",
      "| 21.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20553.0|  46.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1970.0|09302016|  null|  null|     AZ|9.247079603E10|00602|      B2|\n",
      "| 22.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20562.0|  48.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1968.0|09302016|  null|  null|     AZ|9.247848973E10|00608|      B1|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test function\n",
    "immigration_test_file = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat' \n",
    "df_immigration_test = clean_i94_data(immigration_test_file)\n",
    "df_immigration_test.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf()\n",
    "def get_i94port(city):\n",
    "    '''\n",
    "    Input: City name\n",
    "    \n",
    "    Output: Corresponding i94port\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for key in i94port_valid:\n",
    "        if city.lower() in i94port_valid[key][0].lower():\n",
    "            return key\n",
    "\n",
    "# Add iport94 code based on city name\n",
    "df_temp = df_temp.withColumn(\"i94port\", get_i94port(df_temp.City))\n",
    "\n",
    "# Remove data points with no iport94 code\n",
    "df_temp = df_temp.filter(df_temp.i94port != 'null')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean temperature data\n",
    "df_temp = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../../data2/GlobalLandTemperaturesByCity.csv\")\n",
    "# Remove duplicate locations\n",
    "df_temp = df_temp.dropDuplicates(['City', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------------------+-----------+-------------+--------+---------+\n",
      "|        dt|  AverageTemperature|AverageTemperatureUncertainty|       City|      Country|Latitude|Longitude|\n",
      "+----------+--------------------+-----------------------------+-----------+-------------+--------+---------+\n",
      "|1743-11-01|               3.264|                        1.665|  Allentown|United States|  40.99N|   74.56W|\n",
      "|1779-11-01|0.011999999999999985|                        2.714|     Atyrau|   Kazakhstan|  47.42N|   50.92E|\n",
      "|1825-01-01|  26.069000000000003|                         2.16|    Bintulu|     Malaysia|   2.41N|  113.30E|\n",
      "|1825-01-01|              26.517|           2.5839999999999996|Butterworth|     Malaysia|   5.63N|  100.09E|\n",
      "|1845-01-01|              24.995|                        1.871|     Cainta|  Philippines|  15.27N|  120.83E|\n",
      "|1825-01-01|              24.753|           2.1519999999999997|     Ciamis|    Indonesia|   7.23S|  107.84E|\n",
      "|1850-01-01|              22.121|           1.5730000000000002|     Dodoma|     Tanzania|   5.63S|   35.52E|\n",
      "|1840-01-01|  6.2250000000000005|                        2.112|     Fuling|        China|  29.74N|  107.08E|\n",
      "|1841-01-01| -0.3360000000000001|                        2.695|     Fuyang|        China|  32.95N|  115.85E|\n",
      "|1856-01-01|              26.901|                        1.359|        Ife|      Nigeria|   7.23N|    4.05E|\n",
      "+----------+--------------------+-----------------------------+-----------+-------------+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Map out the conceptual data model and explain why you chose that model\n",
    " \n",
    "Star model was used due to the simple structure of data which would make it easier to get the analysis results where we depended on i94port to be the primary key by which linked the fact table to the 2 dimension tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "Step 3: Define the Data Model\n",
    "\n",
    "3.1 Conceptual Data Model\n",
    "\n",
    "Fact Table - All info from the I94 immigration data joined with temperature data of the city on i94port\n",
    "\n",
    "Columns:\n",
    "\n",
    "    i94port = 3-character code of destination city\n",
    "    arrdate = arrival date\n",
    "    i94mode = single digit travel code\n",
    "    depdate = departure date\n",
    "    AverageTemperature = average temperature of destination city\n",
    "    i94visa = reason for immigration\n",
    "    i94yr = 4-digit year\n",
    "    i94mon = numeric month\n",
    "    i94cit = 3-digit code of origin city\n",
    "    \n",
    " Dimension Table -  events from the I94 immigration data.\n",
    "\n",
    "Columns:\n",
    "\n",
    "    i94yr = 4-digit year\n",
    "    i94mon = numeric month\n",
    "    arrdate = arrival date\n",
    "    i94mode = 1-digit travel code\n",
    "    depdate = departure date\n",
    "    i94visa = reason for immigration\n",
    "    i94cit = 3-digit code of origin city\n",
    "    i94port = 3-character code of destination city\n",
    " Dimension Table -  city temperature data.\n",
    "\n",
    "Columns:\n",
    "\n",
    "    i94port = 3-character code of destination city \n",
    "    AverageTemperature = average temperature\n",
    "    City = city \n",
    "    Country = country \n",
    "    Latitude= latitude\n",
    "    Longitude = longitude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "Clean I94 data to create a Spark dataframe df_immigration for each month.\n",
    "\n",
    "Clean temperature data to create Spark dataframe df_temp.\n",
    "\n",
    "Create immigration dimension table from df_immigration and write to parquet file grouped by i94port.\n",
    "\n",
    "Create temperature dimension table from df_temp and write to parquet file grouped by i94port.\n",
    "\n",
    "Create fact table by joining immigration and temperature dimension tables on i94port and write to parquet file grouped by i94port.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Path to I94 immigration data \n",
    "immigration_data = '/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "\n",
    "# Clean I94 immigration data and store as Spark dataframe\n",
    "df_immigration = clean_i94_data(immigration_data)\n",
    "\n",
    "# Extract columns for immigration dimension table\n",
    "immigration_table = df_immigration.select([\"i94yr\", \"i94mon\", \"i94cit\", \"i94port\", \"arrdate\", \"i94mode\", \"depdate\", \"i94visa\"])\n",
    "\n",
    "# Write immigration dimension table to parquet files partitioned by i94port\n",
    "immigration_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create temporary views of the immigration and temperature data\n",
    "df_immigration.createOrReplaceTempView(\"immigration_view\")\n",
    "df_temp.createOrReplaceTempView(\"temp_view\")\n",
    "\n",
    "# Create the fact table by joining the immigration and temperature views\n",
    "fact_table = spark.sql('''\n",
    "SELECT immigration_view.i94yr as year,\n",
    "       immigration_view.i94mon as month,\n",
    "       immigration_view.i94cit as city,\n",
    "\n",
    "   immigration_view.i94port as i94port,\n",
    "       immigration_view.arrdate as arrival_date,\n",
    "       immigration_view.depdate as departure_date,\n",
    "       immigration_view.i94visa as reason,\n",
    "       temp_view.AverageTemperature as temperature,\n",
    "       temp_view.Latitude as latitude,\n",
    "       temp_view.Longitude as longitude\n",
    "FROM immigration_view\n",
    "JOIN temp_view ON (immigration_view.i94port = temp_view.i94port)\n",
    "''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write fact table to parquet files partitioned by i94port\n",
    "fact_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/fact.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration table with 3096313 records\n",
      "Data quality check passed for temperature table with 3490 records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "def quality_check(df, description):\n",
    "    '''\n",
    "    Input: Spark dataframe, description of Spark datafram\n",
    "    Output: Print outcome of data quality check\n",
    "    '''  \n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(description))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(description, result))\n",
    "    return 0\n",
    "quality_check(df_immigration, \"immigration table\")\n",
    "quality_check(df_temp, \"temperature table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "Fact Table - All info from the I94 immigration data joined with temperature data of the city on i94port\n",
    "\n",
    "Columns:\n",
    "\n",
    "    i94port = 3-character code of destination city\n",
    "    arrdate = arrival date\n",
    "    i94mode = single digit travel code\n",
    "    depdate = departure date\n",
    "    AverageTemperature = average temperature of destination city\n",
    "    i94visa = reason for immigration\n",
    "    i94yr = 4-digit year\n",
    "    i94mon = numeric month\n",
    "    i94cit = 3-digit code of origin city\n",
    "    \n",
    " Dimension Table -  events from the I94 immigration data.\n",
    "\n",
    "Columns:\n",
    "\n",
    "    i94yr = 4-digit year\n",
    "    i94mon = numeric month\n",
    "    arrdate = arrival date\n",
    "    i94mode = 1-digit travel code\n",
    "    depdate = departure date\n",
    "    i94visa = reason for immigration\n",
    "    i94cit = 3-digit code of origin city\n",
    "    i94port = 3-character code of destination city\n",
    " Dimension Table -  city temperature data.\n",
    "\n",
    "Columns:\n",
    "\n",
    "    i94port = 3-character code of destination city \n",
    "    AverageTemperature = average temperature\n",
    "    City = city \n",
    "    Country = country \n",
    "    Latitude= latitude\n",
    "    Longitude = longitude\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  Tools used were python pandas for data exploration and spark to build pipelines for big data processing to handle different file formats(SAS, csv, etc) and SQL joins for final database. \n",
    "* Propose how often the data should be updated and why.\n",
    "  \n",
    "  Data should be updated monthly as this is how the tables are set while demographics can be updated annually\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " * The data was increased by 100x.\n",
    "   * Use Spark to process the data efficiently utilizing distributed computing using EMR clusters.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "   * Use Airflow and create a DAG that outlines the logic of the pipeline and controls it.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "   * Use RedShift for data storage to be accessible by multiple individuals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
